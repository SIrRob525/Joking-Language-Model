{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Activation\n",
    "from tensorflow.keras.optimizers.legacy import RMSprop\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "\n",
    "import textwrap\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>joke</th>\n",
       "      <th>body</th>\n",
       "      <th>punchline</th>\n",
       "      <th>score</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>428292</th>\n",
       "      <td>Do all the voices in a schizophrenics head sou...</td>\n",
       "      <td>Asking for a... friend.</td>\n",
       "      <td>Do all the voices in a schizophrenics head sou...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.539959e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11216</th>\n",
       "      <td>A very thirsty man was wandering the desert .....</td>\n",
       "      <td>... when suddenly he spotted a well. With the ...</td>\n",
       "      <td>A very thirsty man was wandering the desert ...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.345755e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513239</th>\n",
       "      <td>I must be great at sex The last girl I was wit...</td>\n",
       "      <td>The last girl I was with liked it so much, she...</td>\n",
       "      <td>I must be great at sex</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.561805e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530464</th>\n",
       "      <td>Why did the students eat their homework? Becau...</td>\n",
       "      <td>Because the teacher said that it was a piece o...</td>\n",
       "      <td>Why did the students eat their homework?</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1.566330e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483438</th>\n",
       "      <td>My relationship with the time traveling girl w...</td>\n",
       "      <td>It was over even before it began.</td>\n",
       "      <td>My relationship with the time traveling girl w...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.554489e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     joke  \\\n",
       "428292  Do all the voices in a schizophrenics head sou...   \n",
       "11216   A very thirsty man was wandering the desert .....   \n",
       "513239  I must be great at sex The last girl I was wit...   \n",
       "530464  Why did the students eat their homework? Becau...   \n",
       "483438  My relationship with the time traveling girl w...   \n",
       "\n",
       "                                                     body  \\\n",
       "428292                            Asking for a... friend.   \n",
       "11216   ... when suddenly he spotted a well. With the ...   \n",
       "513239  The last girl I was with liked it so much, she...   \n",
       "530464  Because the teacher said that it was a piece o...   \n",
       "483438                  It was over even before it began.   \n",
       "\n",
       "                                                punchline  score          date  \n",
       "428292  Do all the voices in a schizophrenics head sou...    2.0  1.539959e+09  \n",
       "11216     A very thirsty man was wandering the desert ...   44.0  1.345755e+09  \n",
       "513239                             I must be great at sex    3.0  1.561805e+09  \n",
       "530464           Why did the students eat their homework?   53.0  1.566330e+09  \n",
       "483438  My relationship with the time traveling girl w...   18.0  1.554489e+09  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"rJokesData/data/preprocessed.csv\")\n",
    "df = df.dropna(axis=0)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_context = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154768303\n",
      "I hope you're all getting your Walter Cronkite jokes in order. He's next.\n",
      "Here's mine.   Ed McMahon, David Carradine, Farrah Fawcett, Michael Jackson,\n",
      "Billy Mays, and Walter Cronkite walk into a bar.   And die.   Your turn.  #  #\n",
      "#  #  #  #  #  #  #  # What is the only thing a woman can say that w\n"
     ]
    }
   ],
   "source": [
    "text = (\" # \" * n_context).join(list(df.loc[:, \"joke\"]))\n",
    "print(len(text))\n",
    "print(textwrap.fill(text[:300], 80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['david', 'carradine', 'farrah', 'fawcett', 'michael', 'jackson', 'billy', 'mays', 'and', 'walter', 'cronkite', 'walk', 'into', 'a', 'bar', 'and', 'die', 'your', 'turn', '#', '#', '#', '#', '#', '#', '#', '#', '#', '#', 'what']\n",
      "32093292\n",
      "134157\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+|#')\n",
    "tokens = tokenizer.tokenize(text.lower())\n",
    "print(tokens[20:50])\n",
    "print(len(tokens))\n",
    "print(len(set(tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokens[:10000] #NOTE: for test purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026\n"
     ]
    }
   ],
   "source": [
    "unique_tokens = set(tokens)\n",
    "tokens_dict = {word: i for i, word in enumerate(unique_tokens)}\n",
    "reverse_tokens_dict = {i: word for i, word in enumerate(unique_tokens)}\n",
    "print(len(unique_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9990/9990 [00:00<00:00, 1460324.71it/s]\n"
     ]
    }
   ],
   "source": [
    "input_words = []\n",
    "next_words = []\n",
    "for i in tqdm(range(len(tokens) - n_context)):\n",
    "    input_words.append(tokens[i:i+n_context])\n",
    "    next_words.append(tokens[i+n_context])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9990/9990 [00:00<00:00, 177262.35it/s]\n"
     ]
    }
   ],
   "source": [
    "X = np.zeros(shape=(len(input_words), n_context, len(tokens_dict)), dtype=bool)\n",
    "y = np.zeros(shape=(len(input_words), len(tokens_dict)), dtype=bool)\n",
    "\n",
    "for i, words in enumerate(tqdm(input_words)):\n",
    "    for j, word in enumerate(words):\n",
    "        X[i, j, tokens_dict[words[j]]] = 1\n",
    "    y[i, tokens_dict[next_words[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components_pca = 100\n",
    "pca_batch_size = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:36<00:00,  9.67s/it]\n"
     ]
    }
   ],
   "source": [
    "pca = IncrementalPCA(n_components=n_components_pca)\n",
    "X = X.reshape(-1, X.shape[-1])\n",
    "\n",
    "#fit X\n",
    "for i in tqdm(range(X.shape[0] // pca_batch_size + 1)):\n",
    "    chunk = X[i * pca_batch_size : (i + 1) * pca_batch_size]\n",
    "    pca.partial_fit(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  5.86it/s]\n"
     ]
    }
   ],
   "source": [
    "#transform X\n",
    "X_transformed = None\n",
    "for i in tqdm(range(X.shape[0] // pca_batch_size + 1)):\n",
    "    chunk = X[i * pca_batch_size : (i + 1) * pca_batch_size]\n",
    "    chunk = pca.transform(chunk)\n",
    "    if X_transformed is None:\n",
    "        X_transformed = chunk\n",
    "    else:\n",
    "        X_transformed = np.vstack((X_transformed, chunk))\n",
    "        \n",
    "X = X_transformed\n",
    "X = X.reshape(-1, n_context, X.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9990, 10, 100)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(n_context, n_components_pca), return_sequences=True))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(len(unique_tokens)))\n",
    "model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "100/100 [==============================] - 4s 22ms/step - loss: 1.1587 - accuracy: 0.7156\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.8342 - accuracy: 0.8068\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.7420 - accuracy: 0.8304\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.7087 - accuracy: 0.8357\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 3s 25ms/step - loss: 0.6311 - accuracy: 0.8512\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 0.5765 - accuracy: 0.8685\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 0.5716 - accuracy: 0.8696\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 3s 25ms/step - loss: 0.5335 - accuracy: 0.8776\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 0.5009 - accuracy: 0.8855\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 3s 25ms/step - loss: 0.4787 - accuracy: 0.8894\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 0.4497 - accuracy: 0.8963\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 0.4447 - accuracy: 0.8958\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 3s 27ms/step - loss: 0.4286 - accuracy: 0.8962\n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 3s 27ms/step - loss: 0.4207 - accuracy: 0.9017\n",
      "Epoch 15/30\n",
      "100/100 [==============================] - 3s 27ms/step - loss: 0.4096 - accuracy: 0.8998\n",
      "Epoch 16/30\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 0.3910 - accuracy: 0.9106\n",
      "Epoch 17/30\n",
      "100/100 [==============================] - 3s 25ms/step - loss: 0.3970 - accuracy: 0.9017\n",
      "Epoch 18/30\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 0.3808 - accuracy: 0.9083\n",
      "Epoch 19/30\n",
      "100/100 [==============================] - 3s 25ms/step - loss: 0.3697 - accuracy: 0.9125\n",
      "Epoch 20/30\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 0.3608 - accuracy: 0.9116\n",
      "Epoch 21/30\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 0.3559 - accuracy: 0.9157\n",
      "Epoch 22/30\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.3524 - accuracy: 0.9137\n",
      "Epoch 23/30\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 0.3458 - accuracy: 0.9167\n",
      "Epoch 24/30\n",
      "100/100 [==============================] - 3s 32ms/step - loss: 0.3430 - accuracy: 0.9154\n",
      "Epoch 25/30\n",
      "100/100 [==============================] - 3s 25ms/step - loss: 0.3432 - accuracy: 0.9145\n",
      "Epoch 26/30\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.3295 - accuracy: 0.9190\n",
      "Epoch 27/30\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.3410 - accuracy: 0.9146\n",
      "Epoch 28/30\n",
      "100/100 [==============================] - 3s 25ms/step - loss: 0.3186 - accuracy: 0.9185\n",
      "Epoch 29/30\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 0.3159 - accuracy: 0.9199\n",
      "Epoch 30/30\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 0.3165 - accuracy: 0.9193\n"
     ]
    }
   ],
   "source": [
    "optimizer = RMSprop(learning_rate=0.01)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "history = model.fit(X, y, batch_size=100, epochs=30, shuffle=True).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_word(input_text, n_best):\n",
    "    input_text = input_text.lower()\n",
    "    X = np.zeros((1, n_context, len(unique_tokens)))\n",
    "    for i, word in enumerate(input_text.split()):\n",
    "        X[0, i, tokens_dict[word]] = 1\n",
    "    X = X.reshape(-1, X.shape[-1])\n",
    "    X = pca.transform(X)\n",
    "    X = X.reshape(-1, n_context, X.shape[-1])\n",
    "        \n",
    "    predictions = model.predict(X)[0] @ pca.components_.T\n",
    "    return np.argpartition(predictions, -n_best)[-n_best:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 76ms/step\n",
      "pitiful\n",
      "everything\n",
      "moment\n",
      "look\n",
      "cautioned\n"
     ]
    }
   ],
   "source": [
    "possible = predict_next_word(\"Why did a cow\", 5)\n",
    "for idx in possible:\n",
    "    print(reverse_tokens_dict[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(input_text, n_words, creativity=3):\n",
    "    word_sequence = input_text.split()\n",
    "    current = 0\n",
    "    for _ in range(n_words):\n",
    "        sub_sequence = \" \".join(tokenizer.tokenize(\" \".join(word_sequence).lower())[current:current+n_words])\n",
    "        try:\n",
    "            choice = reverse_tokens_dict[random.choice(predict_next_word(sub_sequence, creativity))]\n",
    "        except:\n",
    "            choice = random.choice(unique_tokens)\n",
    "        word_sequence.append(choice)\n",
    "        current += 1\n",
    "    return \" \".join(word_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A snail walks into a bar and orders pacific fell death ll dailylaughter dies eternal narwhals both doing both doing narwhals grab pace'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(\"A snail walks into a bar and orders\", 15, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
